{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nitin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing directory\n",
    "import keras \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "path=keras.utils.get_file('nietzsche.txt',origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600901\n"
     ]
    }
   ],
   "source": [
    "text=open(path).read().lower()\n",
    "print('corpus length:',len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequence: 200281\n"
     ]
    }
   ],
   "source": [
    "maxlen=60\n",
    "step=3\n",
    "sentences=[]\n",
    "next_chars=[]\n",
    "for i in range(0,len(text)-maxlen,step):\n",
    "    sentences.append(text[i:i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "print('Number of sequence:',len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: 59\n"
     ]
    }
   ],
   "source": [
    "chars=sorted(list(set(text)))\n",
    "print('Unique characters:',len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization......\n"
     ]
    }
   ],
   "source": [
    "char_indices=dict((char,chars.index(char))for char in chars)\n",
    "print('Vectorization......')\n",
    "x=np.zeros((len(sentences),maxlen,len(chars)),dtype=np.bool)\n",
    "y=np.zeros((len(sentences),len(chars)),dtype=np.bool)\n",
    "for i,sentence in enumerate(sentences):\n",
    "    for t,char in enumerate(sentence):\n",
    "        x[i,t,char_indices[char]]=1\n",
    "    y[i,char_indices[next_chars[i]]]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.LSTM(128,input_shape=(maxlen,len(chars))))\n",
    "model.add(layers.Dense(len(chars),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "             loss='categorical_crossentropy',\n",
    "             optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds,temperature=1.0):\n",
    "    preds=np.array(preds).astype('float64')\n",
    "    preds=np.log(preds)/temperature\n",
    "    exp_preds=np.exp(preds)\n",
    "    preds=exp_preds/np.sum(exp_preds)\n",
    "    probas=np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "200281/200281 [==============================] - 677s 3ms/step - loss: 2.5452\n",
      "--- Generating with seed: \"erman music came afterwards,\n",
      "belongs to romanticism, that is\"\n",
      "----temperature 0.1\n",
      "erman music came afterwards,\n",
      "belongs to romanticism, that is and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and the the the the the the the the the the the the the sore the the the the the the the the the the the the th----temperature 0.2\n",
      " the sore the the the the the the the the the the the the the and and and and and and and and and in the the the the sere the the the the the the the the sore the ind and and in the sore the sure the the serestith and and and and the the the the the the the the the songe the the s and and and and and and and and and and and and in the more the here sond and and and and and the the songere the he the the the the the his in the the the the ingering and and a----temperature 0.5\n",
      "he the the the the his in the the the the ingering and and and and the mentis wo the ers the here tien ant and of whas and af cand mofunt of ald the porentound the the of the the hof the susere se the whel so rome the icmcerte the the and and stoun and mant of wher in ans the moreo s ar ous ince and arite for the uld the herd in of the sinnen in of lesste the the suluthis the esthibe the s alt as\n",
      "elaline seve the she the atte the the coferis an the ell of ----temperature 0.8\n",
      "elaline seve the she the atte the the coferis an the ell of whecillt: and ued the titu of ald inces bfere rathes asthicm sof in and ham is in tien ig pues sogtienose nate wis hore taon wasstenh, thor the ferune ho\n",
      "cultate vely og thimentingis and ghee\n",
      "s buleun . n sserat wiont ranjeuinde.\n",
      " of\n",
      "tinsest of miof suprebco is arliss, the winculise, le sa_thinuth the culllent callise thour the s ous allenting ans is bult andons atros and the surfor is dicatised, epoch 2\n",
      "Epoch 1/1\n",
      " 12160/200281 [>.............................] - ETA: 9:41 - loss: 2.2453"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,60):\n",
    "    print('epoch',epoch)\n",
    "    model.fit(x,y,batch_size=128,epochs=1)\n",
    "    start_index=random.randint(0,len(text)-maxlen-1)\n",
    "    generated_text=text[start_index:start_index+maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "    for temperature in [0.1,0.2,0.5,0.8]:\n",
    "        print('----temperature',temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "        for i in range(400):\n",
    "            sampled=np.zeros((1,maxlen,len(chars)))\n",
    "            for t,char in enumerate(generated_text):\n",
    "                sampled[0,t,char_indices[char]]=1\n",
    "            preds=model.predict(sampled,verbose=0)[0]\n",
    "            next_index=sample(preds,temperature)\n",
    "            next_char=chars[next_index]\n",
    "            generated_text+=next_char\n",
    "            generated_text=generated_text[1:]\n",
    "            sys.stdout.write(next_char)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
